# 大规模问题

这是一个在实际应用当中不可避免的问题。我们目前已经学过的算法中（包括其他课程学习的），有不少算法复杂性度$O(n^3)$。当$n >> 10^5$时，此类算法实际已经不可能执行。此外，当$n$充分大时，对应线性问题的系数矩阵$A$在满存储下是$n^2$个双精度浮点数，其存储量也几乎不可能实现。这里我们强调，如果问题的规模是来源于实际需求，那么是本质且无法避免的。我们在面对大规模问题时，只能尽可能地从模型、算法和技术的角度，尽可能提高现代计算机的实际运算效率，从而得到更高精度（空间和时间上）的求解。

本章内容和参考书第7章相关，但并不完全一致。我们节选第七章的一些算法讨论，并且结合一些的主流计算实现技术。接下去我们首先讨论一个非常具体的计算机技术。

## 大规模稀疏矩阵的实现

稀疏性是绝大多数大规模问题的本质特性。它代表了各自由度之间都是局部依赖，而不是全局两两依赖的。而表现在线性求解器上，则是对应的矩阵是大规模稀疏矩阵。

**定义** 称$m \times n, m > n$阶矩阵$A$是稀疏矩阵，若$A$中的非零元个数是$O(m)$。

对于大规模稀疏矩阵，当我们在计算机内部操作时，我们必须做到：

+ 压缩存储：即以某种方式只存储非零元，并提供全部元素的索引；
+ 快速计算：针对压缩格式提供快速算法，比如，对于$Ap, p \in \mathbb{R}^n$这样的基本运算，我们必须确保其复杂度是$O(m)$的。

在以上两点的基础之上，类似CG法这样的迭代算法，提供了一个求解大规模线性问题
$$
A x = b
$$
的可能算法途径。

## 压缩存储

实际应用当中的具体实现算法很多，我们这里以实现简单，应用广泛的按行压缩存储(Compressed Sparse Row, CSR)格式为例，介绍压缩存储的一般性思路：

+ 只存储非零元；
+ 提供全部元素的快速索引。

我们以矩阵
$$
A = \left[\begin{array}{ccccc}
3.14 & 0 & 0 & 0 & 1.31 \\
0 & 6.1 & 0 & 0 & 0\\
1.9 & 0 & 4.75 & 0 & 0\\
0 & 0 & 0 & 1.1 & 0\\
5.9 & 0 & 0 & 0 & 4.6
\end{array}\right]
$$
为例，首先是压缩存储，它的非零元总数是`nz=8`，因此我们用一个长度为`nz`的`double`数组依次存放全部非零元：

```c++
ele = {3.14, 1.31, 6.1, 1.9, 4.75, 1.1, 5.9, 4.6};
```

这里非零元按行的顺序存放，但同一行的元素互相之间不用保序。在实际工作中，有一种常见的技巧是总是把对角元放在一行的第一个元素位置，此时，一般默认对角元一定非零（非零可以是数值上非零，也可以是操作上将其当作非零元存储，这样这个元素在算法中就被允许从数值零变为非零）。如果我们接受这种策略，那么上述的数组就调整为：

```c++
ele = {3.14, 1.31, 6.1, 4.75, 1.9, 1.1, 4.6, 5.9};
```

接下去我们考虑建立索引。首先由于同一行之间的列排列是无序的，因此我们有必要建立每一个非零元的列索引：

```c++
col = {0, 4, 1, 2, 0, 3, 4, 0};
```

注意这里下标是从$0$开始的，这不但是C/C++语言的习惯，事实上对内存寻址类算法也有优势。然后我们需要用一个索引来标注各行在`col`和`ele`中的起点（注意`col`和`ele`对应元素的下标一定是一致的）：

```c++
row = {0, 2, 3, 5, 6, 8};
```

对于数组`row`，我们规定它的长度是非零元总数`nz`，它的最后一个元素存放`nz`，按照它的定义，它满足以下规律：

+ `row[0]`一定是$0$；
+ `ele`数组中下标为`row[i]:(row[i + 1] - 1)`的元素就是第$i$行的全部元素，$i = 0, 1, 2, \cdots, m-1$；
+ `col`数组中下标为`row[i]:(row[i + 1] - 1)`的元素就是第$i$行的全部元素对应的列标，$i = 0, 1, 2, \cdots, m-1$；
+ 如果每一行的对角元总是存放在第一位，那么必有`col[row[i]] == i`的值为`true`；

利用以上性质，我们可以用如下方法读/写$A_{ij}$：

**读写$A_{ij}$实现**

```c
double read_matrix(const struct MATRIX *mat, int ai, int aj)
{
    int n = mat->pat->n;
    int *row = mat->pat->row;
    int *col = mat->pat->col;
    double *ele = mat->ele;

    int j;
    for (j = row[ai]; j < row[ai + 1]; j ++)
		if (col[j] == aj)
	    	return ele[j];
    return 0.0;
}   
```

这里如果对对角元采取了第一位操作，那么可以专门增加一个判断，如果是对角元，直接返回`ele[row[i]]`。

为描述方便，以下如不加说明我们只考虑方阵，即$m = n$。至此，我们实现了一个对稀疏矩阵内存开销为$O(n)$ ，而读写复杂度为$O(1)$的算法。这里注意我们假设非零元在各行的分布是均匀的，因此每一行的非零元个数是一个$O(1)$量级。

为了配合上述操作，我们实际上需要定义一个基础数据结构来规定矩阵，也就是上面的`struct MATRIX`， 它的具体规定可以是这样：

```c
struct MATRIX
{
    struct PATTERN *pat;	/**< 模板指针. */
    double *ele;			/**< 非零元. */
};
```

这里的模板`struct PATTERN`则是另一个数据结构，规定了稀疏矩阵的结构，也就是具体哪些元素是非零元，哪些不是。讲矩阵和模板分离定义的好处是，很多时候，我们会出现一个模板，多个矩阵的情况。比如如果我们要在稀疏矩阵里定义矩阵相加，那么一个默认的原则是两个矩阵必须有相同的非零元结构。这样加法就只需要将对应非零元相加，因此只是一个$O(n)$的操作。而实际上这样的限制对应用问题来说，也是合理的。这里我直接讨论C代码，而不是Matlab等更高级的代码，主要是因为稀疏矩阵存储和操作这件事情，本质上是要考虑内存如何分配的。这一点在C中可以轻易高效率实现。如果没有C基础的同学，可以将上述代码当作伪代码看待。此外，我们在任何作业或考试中，不会对这一点有要求。这里模板的具体规定如下：

```c
struct PATTERN 
{
    int n;					/**< 行数. */
    int m;					/**< 列数. */
    int *row;				/**< 行指标. */
    int *col;				/**< 列指标. */
    int is_compressed;		/**< 是否压缩. */
    struct node *registed;	/**< 采用该模板的矩阵. */
};
```

所有设置和我们之前讨论的一致。我们这里实际上回避了一个重要的关键问题，稀疏矩阵是如何初始化的。或者我们这里需要强调，介于矩阵规模，我们永远也不能有这样的想法：将一个满阵转换为稀疏阵（确实，Matlab提供了这样的功能，参见`sparse`，但它只是为了调试）。甚至，以下的代码也是禁止的：

```c
for (i = 0; i < n; i++)
    for (j = 0; j < n; j++)
        ...
```

这样的代码本质上将复杂度提升到了$O(n^2)$，在大规模情形下是不可接受的。

在实际应用场合，大规模稀疏矩阵应该直接从问题产生。具体的问题可能是一个优化问题，也可能是一个基于微分方程的物理问题。具体情形参见参考书

+ Iterative Methods for Sparse Linear Systems, 2nd. ed.

我们在适当的时候再结合算法引入具体的例子。接下去我们再考虑一个具体的算子实现：$Ap$，即矩阵乘向量。我们知道，这个算子是CG法的核心，在这个算子的基础上，我们能够方便地构建CG求解器，从而实现算子作用$A^{-1}q$。

**算子Ap实现**

```c
int mat_m_vec(const struct MATRIX *mat, const double *iv, double *ov)
{
    int i, j;
    double s;
    for (i = 0; i < mat->pat->n; i++)
    {
	s = 0;
	for (j = mat->pat->row[i]; j < mat->pat->row[i + 1]; j++)
	    s += mat->ele[j] * iv[mat->pat->col[j]];
	ov[i] = s;
    }
    return 0;
};
```

这里`iv`是输入向量，而`ov`是输出。这里我们看到循环忽略了全部零元，因此总计算量是$O(n)$。本质上，在大规模稀疏矩阵的基本操作中，$O(n^2)$的代价是不可接受的。所有的存储和操作，都围绕着这一点。感兴趣的同学可以考虑一下，如何在$O(n^2)$的时间代价内，完成两个矩阵相乘的操作。即
$$
A * B = C,
$$
这里$A$，$B$和$C$都是大规模稀疏矩阵，且具有不同的模板。

我们已经通过CSR格式简单介绍了大规模稀疏矩阵压缩存储和快速计算的思想。CSR只是一种最基础当然也是最常见的实现方案。这里要指出的是它非常适合处理需要不断取矩阵某一行的操作，但是它取一列的复杂度是$O(n^2)$。因为你必须去每一行搜索是否存在你要的那一列。也即，在CSR格式下，取列的操作是严禁的。因此如果算法需要取列，那么必须先将按行压缩存储，改为按列压缩存储（Compressed Sparse Column, CSC）。这个操作通过矩阵转置完成。事实上，在这类算法中，我们几乎总是同时保留两种压缩格式的数据。更多的压缩存储格式，请自行阅读参考文献。

## 具体操作的例子

下面我们看一个具体操作的例子，并解决矩阵初始化的问题。然后我们继续在CG框架中实现一种新的预处理策略：对称超松弛迭代法(symmetric successive overrelaxation method, SSOR)。

让我们回顾第六周的作业，我们得到了一个25万阶的矩阵，这个矩阵读入Matlab以后，你会发现它提供的是一种
$$
(i, j, A_{ij})
$$
的三元数来表示一个稀疏矩阵的非零元，这里$i$表示行号，$j$表示列号，$A_{ij}$表示对应非零元的值。这是一种常见的情况，那么如果假设我们已经有了全部的非零元三元数信息，如何才能在一个程序中读入？你不能先准备一个二元数组（满阵），然后再转成压缩格式，那样会导致一个$O(n^2)$的操作，而是必须直接生成一个压缩格式的矩阵。仔细思考这件事情的意义在于真正理解压缩格式的贡献。

**判断每一行至多有几个非零元**

首先我们需要把所有数据读一遍，统计每一行的非零元个数，这里我们只需要记录非零元数目最多的一行的非零元个数就行了。这里我们假设，非零元在每一行都是均匀分布的，因为非零元总数是$O(n)$，而一共有$n$行，故每一行的非零元个数平均是一个常数，这个常数我们称为`nzmax`。在这种情况下，我们首先将模板初始化成一个每一行都有`nzmax`个非零元的模板（这里没必要生成矩阵，先初始化模板就行），同时，我们并不确定每一个非零元的列号，事实上，我们连某一行到底有几个非零元都不清楚，而是只知道我们给每一行都留下了足够多的非零元位置就行了。因此，这里的列号一律用`-1`表示尚未确定的列号。这一过程的代码：

```c
int init_pattern(struct PATTERN *pattern, int n, int m, int nzmax)
{
    int i, j;
    pattern->n = n;
    pattern->m = m;
    if ((pattern->row = (int*)malloc(sizeof(int) * (n + 1))) == NULL ||
	(pattern->col = (int*)malloc(sizeof(int) * (n * nzmax))) == NULL)
    {
		printf ("Out of memory!\n");
		exit(-1);
    }  /*不要去管复杂的内存申请，这里就是给将row长度设置为(n + 1)，col长度设置为n*nzmax*/
    for (i = 0; i < n; i++)
    {
		pattern->row[i] = i * nzmax;
		pattern->col[pattern->row[i]] = i;
		for (j = i * nzmax + 1; j < (i + 1) * nzmax; j++)
	    	pattern->col[j] = -1;
    }	/*第i行的起点为i*nzmax，每一行都有nzmax个空间，但列号全部是-1*/
    pattern->row[n] = n * nzmax;	/*非零元总数为n*nzmax*/
    pattern->is_compressed = 0;		
    pattern->registed = NULL;
    return 0;
};
```

这里因为模板有大量元素尚未确定是否存在和列号，所以处于未压缩状态（`is_compressed = 0`）。这一状态在所有元素确定之后，手工改变。

如果非零元在每一行的分布是不均匀的，比如可能出现某几行几乎全满，而其他行几乎是空的这种情况，则我们这里介绍的初始化不适用，要另外设计。比如找到那些满的行，单独处理。

**确定哪一些元素会正真使用**

接下去做的事情似乎很愚蠢，就是把刚刚读过的全部元素再从头读一遍，这次一边读，一边在初始模板中记录它们的位置。这里注意同一行元素可以乱序，除了对角元一般放第一位以外。考虑到非零元总数是$O(n)$，所以重复读了两遍，算法的时间仍然是$O(n)$的。之所以要读两遍，是因为在很多场合，比如动态建模，或者微分方程求解，我们并不能一口气获得全部非零元结构化的信息，而是每次只能获得“下一个元素”的信息。这种情况下，这种方式反而具有最佳的可读性和平均效率。参考代码如下：

```c
int set_pattern(struct PATTERN *pattern, int pi, int pj)
{
    int j, flag;
    if (pi == pj)
		return 0;
    else
    {
		flag = 0;
		for (j = pattern->row[pi] + 1; j < pattern->row[pi + 1]; j++)
		{
	    	if (pattern->col[j] == -1)
	    	{
				pattern->col[j] = pj;
				flag = 1;
				break;
	    	}
		}	/*寻找一个未使用的位置来记录新的元素*/
		if (flag == 0)
		{
	    	printf ("Pattern error!\n");
	    	exit(-1);
		}	/*找不到空位是一个异常*/
    }
    return 0;
};
```

**压缩模板**

现在的情况是，我们已经记录了全部非零元的位置，但是仍然存在一些空位，也就是列标为`-1`的元素。我们现在需要将这些空间“压缩”掉。

注：由于内存的部分释放实际会占用一定的机器时间，因此很多时候，我们只是标记这些实际未使用的空间，而不去回收它们。

这个算法对学过《数据结构》或《算法导论》的同学应该很简单，我们用一个读指`rp`针过滤一遍全部元素，直接跳过下标为`-1`的元素，而将下标不是`-1`的元素复制到另一个全局元素遍历写指针`wp`指向的位置，`wp`每接收一个复制元素，就向前前进一个元素的位置。这里要注意同时必须调整`row`元素的位置，因为每一行的起始位置变化了。参考代码如下：

```c
int compress_pattern(struct PATTERN *pattern)
{
    int rp = 0;
    int wp = 0;
    int old_row = 0;
    int i, j;
    for (i = 0; i < pattern->n; i++)
    {
		for (j = old_row; j < pattern->row[i + 1]; j++)
		{
	    	if (pattern->col[j] != -1)
	    	{
				pattern->col[wp] = pattern->col[rp];
				wp++;
				rp++;
	    	}
	    	else
				rp++;
		}
		old_row = pattern->row[i + 1];
		pattern->row[i + 1] = wp;
    }
    pattern->is_compressed = 1;
    return 0;
};
```

完成这个操作后，记得将`is_compressed`设置成`1`。一个矩阵模板一旦压缩完成，在整个生命周期内，结构一般不得再改动，否则可能带来数据混乱（特别是一个模板可能配置了不止一个矩阵）。不过我在这里留下了一个`registed`的成员指针，它其实是一个链表的头，记录了全部引用它的矩阵。也就是说，逻辑上，你可以通过这个链表去追溯全部使用了它的矩阵。不过还是不建议真这么去做。计算数学领域编程的一个基本逻辑是越简单越好，不要纠结太多细枝末节。

**SSOR预处理**

现在我们能够读取矩阵，拥有矩阵乘向量算子，而同一模板矩阵矩阵相加和向量相乘运算是简单的。因此我们已经可以完成CG法求一个矩阵逆算子作用的程序。从稀疏矩阵压缩格式我们可以体会到，不完全Cholesky分解这样的操作，在稀疏矩阵场合是很容易实现的。这里顺便再介绍一种预处理策略——对称超松弛迭代，或者简称为SSOR。

我们知道，线性方程组求解的迭代算法，基本上脱胎于两种基本算法，Jacobi迭代和Gauss-Sedial(GS)迭代。（参见：G. H. Golub, C. F. Van Loan, Matrix Computations, 4th. ed., The Johns Hopkins University Press, Baltimore, 2013, ch. 11, p. 611.）其中，对线性问题
$$
Ax = b,
$$
的迭代过程，Gauss-Sedial迭代的分量迭代格式可写成：
$$
x_i^{(k + 1)} = \frac{b_i - \sum_{j = 1}^{i - 1}a_{ij}x_j^{(k+1)}-\sum_{j = i+1}^{n}a_{ij}x_j^{(k)}}{a_{ii}},
$$
这里，$x_i^{(k)}$表示$x$的第$i$个分量在第$k$步迭代的值，而$a_{ij}$则表示$A$的第$(i,j)$位置的元素。$i, j = 1, 2, \cdots, n$，$k = 0, 1, \cdots$。

这里说明一下Gauss-Sedial迭代，是一种收敛非常缓慢的迭代法，一般不能直接使用。正确的使用方式之一是增加松弛因子，也就是将迭代格式改为：
$$
x_i^{(k + 1)} = (1 - \omega)x_i^{(k)} + \omega\frac{b_i - \sum_{j = 1}^{i - 1}a_{ij}x_j^{(k+1)}-\sum_{j = i+1}^{n}a_{ij}x_j^{(k)}}{a_{ii}},
$$
这里的$\omega \in (0, 2)$称为松弛因子，它提示GS迭代每一步更新的过头了一点，因此掺上一点旧值，反而能起到迭代加速的效果。这就是所谓的超松驰迭代(Successive Over Relaxation, SOR)。然而，如果把上述变换看作线性算子作用，也就是矩阵乘向量，即将$A$分裂成
$$
A = D - E - F
$$
的形式，其中$D$是$A$的对角元构成的对角阵，$E$和$F$分别是$A$的对角线以下和以上部分符号取反。那么迭代法的一般算子形式可以表示成：
$$
x^{(k+1)} = G x^{(k)} + f.
$$
对GS迭代，具体的形式是
$$
G_{GS} = I - (D - E)^{-1}A,
f_{GS} = (D - E)^{-1}b.
$$
这里我们看到GS的算子作用显然是非对称的。而SOR迭代也继承了GS迭代算子作用不对称的问题
$$
G_{SOR} = I - \left(\frac{1}{\omega}(D - \omega E)\right)^{-1}A, f_{SOR} = \left(\frac{1}{\omega}(D - \omega E)\right)^{-1} b.
$$
因此也无法应用在要求矩阵保持对称的CG迭代预处理场合。一个简单而直接的处理，是将一步完整的SOR迭代，分裂成两步，从而获得一个对称的等效形式。这种做法就被称为对称超松驰迭代(Symmetric Successive Over Relaxation，SSOR)，即
$$
G_{SSOR} = I - \left(\frac{1}{\omega(2 - \omega)}(D - \omega E)D^{-1}(D - \omega F)\right)^{-1}A, \\ f_{SSOR} = \left(\frac{1}{\omega(2 - \omega)}(D - \omega E)D^{-1}(D - \omega F)\right)^{-1}b.
$$

这种对称的算子形式，相当于确保我们的预处理阵$M$实际上的取值为
$$
M = \left(\frac{1}{\omega(2 - \omega)}(D - \omega E)D^{-1}(D - \omega F)\right)^{-1},
$$
从而使得$MA$称为对称矩阵（算子），进而是CG迭代可以继续。上述迭代看似非常复杂，但其实这些形式都是针对大规模稀疏矩阵设计的，在实际编程的时候，其实非常方便。比如一个基于CSR格式的SSOR预处理可以如此实现：

```c
int pc_ssor(const struct MATRIX *mat, const double *v, double *w, double omg)
{
    int i, j;
    int n = mat->pat->n;
    int *row = mat->pat->row;
    int *col = mat->pat->col;
    double *ele = mat->ele;
    for (i = 0; i < n; i++)
    {
		w[i] = v[i];
		for (j = row[i] + 1; j < row[i + 1]; j++)
		{
	    	if (col[j] > i)
				continue;
	    	else
				w[i] -= omg * ele[j] * w[col[j]] / ele[row[col[j]]];
		}
    }
    for (i = n - 1; i >= 0; i--)
    {
		for (j = row[i] + 1; j < row[i + 1]; j++)
		{
	    	if (col[j] < i)
				continue;
	    	else
				w[i] -= omg * ele[j] * w[col[j]]; 
		}
		w[i] /= ele[row[i]];
    }
    return 0;
};
```

从编程角度看，这段代码显得过于繁琐，缺乏技巧。但是它直接对应算法，便于阅读和理解。这是一种计算数学教学过程中的常用策略。同时，它在时间复杂度上并没有损失，所以它实际上确实可以改善CG迭代效率。参见完整的`main.c`程序。

## 最佳逼近模型

现在我们来考虑一个更加一般化的实际问题，寻找一个目标函数在指定空间的最佳逼近元。比如$\sin(\pi x)$在$[0, 1]$的分段线性空间上的最佳逼近元。我们在插值、逼近、最小二乘、曲线拟合等多个场合学习过这个问题，现在我们用优化的视野来观察这个问题，并得到一个更加一般的算法框架。为方便起见，我们的目标空间始终定在$[0, 1]$上的分段线性空间（未必均匀划分），但这个思路可以容易地推广到任意可计算函数和Hilbert空间（Sobolev空间更加合适），甚至可以用来求解微分方程。在微分方程数值求解领域，该方法有一个更加著名的名称——有限元法(Finite Element Method)。需要指出，我们这里只讨论一种最简单的情形，并不是完整的有限元方法，也缺乏必要的理论分析和保证，只是一个简化的例子。

假设我们将$[0, 1]$空间划分成$x_0 = 0 < x_1 < x_2 < \cdots < x_n = 1$共$n$个$[x_i, x_{i + 1}]$区间，$i = 0, 1, \cdots, n - 1$。定义基函数
$$
\begin{equation}
\phi_i(x) = \left\{\begin{array}{ll}
\displaystyle \frac{x - x_{i - 1}}{x_i - x_{i - 1}},&x \in [x_{i - 1}, x_i],\\
\displaystyle \frac{x_{i + 1} - x}{x_{i + 1} - x_i},&x \in [x_i, x_{i + 1}],\\
0,& \mbox{其他.}
\end{array}\right.
\tag{7.1}
\end{equation}
$$
于是有
$$
\phi_i(x_j) = \delta_{ij}, i, j = 1, \cdots, n - 1.
$$
特别地，规定边界情形
$$
\begin{equation}
\phi_0(x) = \left\{\begin{array}{ll}
\displaystyle \frac{x_1 - x}{x_1 - x_0},&x \in [x_0, x_1],\\
0,& \mbox{其他.}
\end{array}\right.
\tag{7.2}
\end{equation}
$$
以及
$$
\begin{equation}
\phi_n(x) = \left\{\begin{array}{ll}
\displaystyle \frac{x - x_n}{x_{n - 1} - x_n},&x \in [x_{n - 1}, x_n],\\
0,& \mbox{其他.}
\end{array}\right.
\tag{7.3}
\end{equation}
$$
这样就构成一个完整的$[0, 1]$上划分为$x_0 = 0 < x_1 < x_2 < \cdots < x_n = 1$的分片线性函数空间
$$
\begin{equation}
H_1^{[0, 1]} \overset{\mathrm{def}}= \left\{u \left| u = \sum_{i = 0}^n u_i \phi_i(x), u_i \in \mathbb{R}\right.\right\}.
\tag{7.4}
\end{equation}
$$
现在对$[0, 1]$上的平方可积函数$f$，我们寻找$H_1^{[0, 1]}$种的最佳平方逼近元，也即
$$
\begin{equation}
\min_{u \in H_1^{[0, 1]}} \|u - f\|_2^2.
\tag{7.5}
\end{equation}
$$
这个问题本质上就是一个最小二乘问题，我们甚至可以直接写出它的正规方程组。这里我们稍微加以推导，对上式关于$u = (u_0, u_1, \cdots, u_n)$（因为是有限维，我们这里不区分$H_1^{[0, 1]}$中的成员函数和其向量表示）求其梯度的零点，有
$$
\begin{array}{ll}
&\displaystyle \frac{\partial}{\partial u_j}\int_0^1\left(\sum_{i = 0}^n u_i\phi_i(x) - f(x)\right)^2dx = 0\\
\Rightarrow&\displaystyle\int_0^1\frac{\partial}{\partial u_j}\left(\sum_{i = 0}^nu_i\phi_i(x) - f(x)\right)^2dx = 0\\
\Rightarrow&\displaystyle\int_0^12\left(\sum_{i = 0}^nu_i\phi_i(x) - f(x)\right)\phi_j(x)dx = 0\\
\Rightarrow&\displaystyle\sum_{i = 0}^n\int_0^1u_i\phi_i(x)\phi_j(x)dx - \int_0^1f(x)\phi_jdx = 0\\
\Rightarrow&\displaystyle\sum_{i = 0}^n\int_0^1u_i\phi_i(x)\phi_j(x)dx = \int_0^1f(x)\phi_jdx \\


\end{array}
$$
若将其写成矩阵向量形式，则有
$$
\begin{equation}
K u = f,
\tag{7.6}
\end{equation}
$$
其中
$$
K_{ij} = \int_0^1\phi_i(x)\phi_j(x)dx,
$$
是$n + 1$阶系数矩阵，注意对$|i - j| > 1$有$K_{ij} = 0$。也即实际上$K$是三对角矩阵，这是由一维的对称性决定的。对于二维的三角形剖分或四边形剖分，以及更高的维数，$K$是稀疏的，但并不是带宽矩阵，而且$K$的非零元分布和节点编号有关（也即存在使$K$非零元最集中于对角线附近的最佳编号）。(7.6)的右端向量的分量为
$$
f_i =\int_0^1f(x)\phi_jdx,
$$
而$u = (u_0, u_1, \cdots, u_n)$为未知向量。事实上，方程组(7.6)就是问题(7.5)的正规方程组。
